{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting City and Country Information from News Headlines\n",
    "\n",
    "## Parsing the News Headlines\n",
    "\n",
    "__Objective__: Find any city and/or country names mentioned in each of the news headlines. We will use these names to find geographic locations of the headlines in the next section. \n",
    "\n",
    "__Workflow__:\n",
    "1.\tLoad in the headline data and examine it for any data quality issues.\n",
    "    - Use any library/data structure to read in the headlines\n",
    "    - Read through some of the headlines and identify potential problems\n",
    "2.\tUsing regular expressions and the cities and countries within the geonamescache library, match any cities/countries within each headline. \n",
    "    -\tMake sure to normalize headlines and city/country names by removing accent marks. This can be done with the unidecode library.\n",
    "    -\tWatch out for multiple cities in a headline and matches on short words! We want the match to be on the entire city – for example San Marino – and not a partial match – San.\n",
    "3.\tPut the extracted data into a pandas DataFrame with three columns: headline, city, country.\n",
    "4.\tMake sure there were no issues with the extraction by sampling some of the headlines and examining the city and country names. \n",
    "    -\tOne method for finding problems is to look for the most common names and see if there are any issues.\n",
    "5.\tOnce you are confident you’ve found all the cities/countries in each headline, save the DataFrame for the next part.\n",
    "\n",
    "__Deliverable__:\n",
    "\n",
    "The deliverable is a Jupyter Notebook documenting your workflow as you take the headlines.txt file, extract the city/country names, and put the results into a Pandas DataFrame. This DataFrame will allow us to quickly perform analysis on the headlines and geographic data that we will find in the next part. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in the data\n",
    "\n",
    "We can read in all the headlines as a list and strip out the newline marks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-10T17:07:26.332339Z",
     "start_time": "2019-10-10T17:07:26.322639Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Zika Outbreak Hits Miami',\n",
       " 'Could Zika Reach New York City?',\n",
       " 'First Case of Zika in Miami Beach',\n",
       " 'Mystery Virus Spreads in Recife, Brazil']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"../data/headlines.txt\") as file:\n",
    "    data = [headline.strip() for headline in file]\n",
    "    \n",
    "data[:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cities and Countries from GeonamesCache\n",
    "\n",
    "Now we'll create a list of city names and country names using the `geonamescache` Python library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-10T17:07:26.362101Z",
     "start_time": "2019-10-10T17:07:26.354757Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Andorra', 'United Arab Emirates', 'Afghanistan', 'Antigua and Barbuda']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import geonamescache\n",
    "\n",
    "gc = geonamescache.GeonamesCache()\n",
    "countries = [country[\"name\"] for country in gc.get_countries().values()]\n",
    "countries[:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can do the same with cities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-10T17:07:26.445981Z",
     "start_time": "2019-10-10T17:07:26.379850Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Andorra la Vella', 'Umm Al Quwain City', 'Ras Al Khaimah City', 'Zayed City']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cities = [city['name'] for city in gc.get_cities().values()]\n",
    "cities[:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Duplicate Cities\n",
    "\n",
    "There are cities in `geonamescache` that are recorded more than once in different countries (or even multiple times in the same country). We'll have to figure out how to handle this later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-10T17:07:26.458882Z",
     "start_time": "2019-10-10T17:07:26.447422Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Springfield', 8),\n",
       " ('San Pedro', 7),\n",
       " ('Richmond', 7),\n",
       " ('San Fernando', 7),\n",
       " ('Mercedes', 6),\n",
       " ('La Paz', 6),\n",
       " ('Victoria', 6),\n",
       " ('San Francisco', 6),\n",
       " ('Auburn', 6),\n",
       " ('Santa Cruz', 6)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "city_counts = Counter(cities)\n",
    "city_counts.most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One city is even mentioned 8 times! This could cause an issue - we'll handle the duplicate cities in the second part of this project when we match cities to locations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing Accent Marks\n",
    "\n",
    "We need to remove the accent marks from the lists of countries and cities. For this we will use the `unidecode` library. (Method from this [Stack Overflow answer](https://stackoverflow.com/questions/517923/what-is-the-best-way-to-remove-accents-in-a-python-unicode-string).) For the cities and the countries from geonamescache, we will map the unaccented name to the accented name. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-10T17:07:26.499178Z",
     "start_time": "2019-10-10T17:07:26.460673Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Āsmār'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import unidecode\n",
    "\n",
    "country_accent_mapping = {\n",
    "    unidecode.unidecode(country): country for country in countries\n",
    "}\n",
    "\n",
    "city_accent_mapping = {\n",
    "    unidecode.unidecode(city): city for city in cities\n",
    "}\n",
    "city_accent_mapping[\"Asmar\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the accented city names have been mapped to their unaccented versions. Let's also remove the accent marks from the headlines so we can match on the unaccented version (in the `keys` of the mapping.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-10T17:07:26.504633Z",
     "start_time": "2019-10-10T17:07:26.500743Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['More Zika patients reported in Indang',\n",
       " 'Suva authorities confirmed the spread of Rotavirus',\n",
       " 'More Zika patients reported in Bella Vista',\n",
       " 'Zika Outbreak in Wichita Falls']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = [unidecode.unidecode(headline) for headline in data]\n",
    "data[-4:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can look for the unaccented city and country names in the headlines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Searching for Cities and Countries\n",
    "\n",
    "Next, we'll search each headline for any cities and/or countries. To do this, we use regular expressions created from the unaccented cities and countries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-10T17:07:26.526745Z",
     "start_time": "2019-10-10T17:07:26.523396Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 23022 cities to look through.\n",
      "There are 252 countries to look through.\n"
     ]
    }
   ],
   "source": [
    "# Create list of cities and countries\n",
    "unaccented_cities = list(city_accent_mapping.keys())\n",
    "unaccented_countries = set(country_accent_mapping.keys())\n",
    "\n",
    "print(f\"There are {len(unaccented_cities)} cities to look through.\")\n",
    "print(f\"There are {len(unaccented_countries)} countries to look through.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regular Expressions\n",
    "\n",
    "The two regular expressions for searching the headlines will consist of all the cities and all the countries. We want to be careful about two things:\n",
    "\n",
    "1. Match entire words. The solution for this is use the `\\b` tag as [explained in this answer](https://stackoverflow.com/questions/15863066/python-regular-expression-match-whole-word). Basically, we have to surround our regular expression words with `\\b` like so `\\bcity_name\\b`.\n",
    "2. Find the entire city. For some cities, like \"San Jose\", we will end up matching \"San\" because there is a city in the list with \"San\" and regular expressions are greedy, returning the first complete match. Therefore, we need to sort the lists of cities and countries by descending length before creating the regular expressions. This ensures we match the longest city and country instead of getting a partial match."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Partial Match Issue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-10T17:07:26.575612Z",
     "start_time": "2019-10-10T17:07:26.572664Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<re.Match object; span=(0, 3), match='San'>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "problem_city = 'San Jose'\n",
    "re.search('\\\\bSan\\\\b|\\\\bSan Jose\\\\b', problem_city)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we see the second problem. We've matched only `San` instead of the entire city name. To correct this, we change the ordering of the regular expression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-10T17:07:26.598662Z",
     "start_time": "2019-10-10T17:07:26.595793Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<re.Match object; span=(0, 8), match='San Jose'>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.search('\\\\bSan Jose\\\\b|\\\\bSan\\\\b', problem_city)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Issue solved! If we first sort the cities from longest to shortest, we will be sure to match the entire city name."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sort Cities and Countries by Length\n",
    "\n",
    "We can sort the cities and countries first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-10T17:07:26.644746Z",
     "start_time": "2019-10-10T17:07:26.637049Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Chak Two Hundred Forty-nine Thal Development Authority',\n",
       " 'Dolores Hidalgo Cuna de la Independencia Nacional']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unaccented_cities = sorted(unaccented_cities, key=lambda x: len(x), reverse=True)\n",
    "unaccented_cities[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-10T17:07:26.649062Z",
     "start_time": "2019-10-10T17:07:26.645948Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['South Georgia and the South Sandwich Islands',\n",
       " 'United States Minor Outlying Islands']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unaccented_countries = sorted(unaccented_countries, key=lambda x: len(x), reverse=True)\n",
    "unaccented_countries[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These lists are now in order from longest to shortest names. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constructing the Regular Expressions\n",
    "\n",
    "We construct the regular expressions by joining together the list of strings. The words are separated with a `|` for the or symbol in a regular expression. We also use the `\\b` tag to make sure to match on entire words (beginning and end.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-10T17:07:26.690025Z",
     "start_time": "2019-10-10T17:07:26.686308Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'-Baume\\\\b|\\\\bTamuning-Tumon-Harmon Village\\\\b|\\\\bTultitlan de Mariano Escobedo\\\\b|\\\\bSan Bernardino Tlaxcalancingo\\\\b|\\\\bSan Francisco Tlalcilalcalpan\\\\b|\\\\bFraccionamiento Ciudad Olmeca\\\\b|\\\\bPresidencia Roque Saenz Pena\\\\b|\\\\bZurich (Kreis 11) / Oerlikon\\\\b|\\\\bSan Fernando de Monte Cristi\\\\b|\\\\bPuerto Francisco de '"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "city_regex = r'\\b|\\b'.join(unaccented_cities)\n",
    "city_regex[1500:1800]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test out the city regex."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-10T17:07:27.442632Z",
     "start_time": "2019-10-10T17:07:26.711042Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "More Zika patients reported in Custodia\n",
      "Custodia \n",
      "\n",
      "Tokyo Encounters Severe Symptoms of Meningitis\n",
      "Tokyo \n",
      "\n",
      "Zika Troubles come to Kampong Cham\n",
      "Kampong Cham \n",
      "\n",
      "19 new Zika Cases in Sengkang\n",
      "Sengkang \n",
      "\n",
      "Mumbai's Health Minister warns of more Zika cases\n",
      "Mumbai \n",
      "\n",
      "Varicella re-emerges in Lagos\n",
      "Lagos \n",
      "\n",
      "Mumbai's Health Minister warns of more Zika cases\n",
      "Mumbai \n",
      "\n",
      "Milwaukee authorities confirmed the spread of Rhinovirus\n",
      "Milwaukee \n",
      "\n",
      "Zika cases concern Charlotte residents\n",
      "Charlotte \n",
      "\n",
      "Four cases of Zika in Hidalgo County\n",
      "Hidalgo \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.random.seed(50)\n",
    "\n",
    "test_headlines = np.random.choice(data, 10)\n",
    "\n",
    "for test_headline in test_headlines:\n",
    "    print(test_headline)\n",
    "    match = re.search(city_regex, test_headline)\n",
    "    if match:\n",
    "        print(match.group(0), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That seems to work well. We do have an issue with the last headline, but there will always be some data quality problems.\n",
    "\n",
    "Let's make a regular expression for the countries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-10T17:07:27.446798Z",
     "start_time": "2019-10-10T17:07:27.443789Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'South Georgia and the South Sandwich Islands\\\\b|\\\\bUnited States Minor Outlying Islands\\\\b|\\\\bBonaire, S'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "country_regex = r\"\\b|\\b\".join(unaccented_countries)\n",
    "country_regex[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-10T17:07:27.459541Z",
     "start_time": "2019-10-10T17:07:27.448294Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Longwood volunteers spreading Zika awareness\n",
      "More Zika cases in Soyapango\n",
      "Spike of Dengue Cases in Stockholm\n",
      "Case of Measles Reported in Vancouver\n",
      "Zika arrives in Belmopan\n",
      "Outbreak of Zika in Colombo\n",
      "Zika symptoms spotted in Arlington\n",
      "Malaria re-emerges in Boise\n",
      "Southampton Patient in Critical Condition after Contracting Tuberculosis\n",
      "Manassas Encounters Severe Symptoms of Measles\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(100)\n",
    "test_headlines = np.random.choice(data, 10)\n",
    "\n",
    "for test_headline in test_headlines:\n",
    "    print(test_headline)\n",
    "    match = re.search(country_regex, test_headline)\n",
    "    if match:\n",
    "        print(match.group(0), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No country matches! We might not have many countries to work with in this project. Let's test both the city and country regex on a headline with a city and a country."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-10T17:07:27.472184Z",
     "start_time": "2019-10-10T17:07:27.461566Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mystery Virus Spreads in Recife, Brazil\n",
      "Recife\n",
      "Brazil\n"
     ]
    }
   ],
   "source": [
    "test_headline = data[3]\n",
    "print(test_headline)\n",
    "print(re.search(city_regex, test_headline).group(0))\n",
    "print(re.search(country_regex, test_headline).group(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For any matches, we can look up the accented version in our mapping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-10T17:07:27.475627Z",
     "start_time": "2019-10-10T17:07:27.473193Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recife\n",
      "Brazil\n"
     ]
    }
   ],
   "source": [
    "print(city_accent_mapping[\"Recife\"])\n",
    "print(country_accent_mapping[\"Brazil\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neither of these have accents. \n",
    "\n",
    "### City and Country Regular Expression Function\n",
    "\n",
    "Let's encapsulate the logic to find city and country names into a function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-10T17:07:27.480900Z",
     "start_time": "2019-10-10T17:07:27.476878Z"
    }
   },
   "outputs": [],
   "source": [
    "def find_city_and_country_in_headline(headline):\n",
    "    \"\"\"\n",
    "    Find the city(s) and/or country(s) in a text headline.\n",
    "    \n",
    "    :param headline: string for headline\n",
    "    \n",
    "    :return dict: a dictionary mapping the headline to city(s) and/or countries.\n",
    "    \"\"\"\n",
    "    city_match = re.search(city_regex, headline)\n",
    "    country_match = re.search(country_regex, headline)\n",
    "    cities = None if not city_match else city_match.group(0)\n",
    "    countries = None if not country_match else country_match.group(0)\n",
    "    return dict(headline=headline, countries=countries, cities=cities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test this out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-10T17:07:27.494591Z",
     "start_time": "2019-10-10T17:07:27.482603Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'headline': 'Mystery Virus Spreads in Recife, Brazil',\n",
       " 'countries': 'Brazil',\n",
       " 'cities': 'Recife'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_city_and_country_in_headline(data[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-10T17:07:27.506403Z",
     "start_time": "2019-10-10T17:07:27.496933Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'headline': 'Could Zika Reach New York City?',\n",
       " 'countries': None,\n",
       " 'cities': 'New York City'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_city_and_country_in_headline(data[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Things look pretty good at this point. Let's move on to using this for all headlines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply Regular Expression to All Headlines\n",
    "\n",
    "Now we apply this function to all headlines. We'll end up with a list containing all the headlines and and cities or countries in the headlines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-10T17:07:31.515323Z",
     "start_time": "2019-10-10T17:07:27.508071Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'headline': 'Authorities are Worried about the Spread of Varicella in Clovis',\n",
       "  'countries': None,\n",
       "  'cities': 'Clovis'},\n",
       " {'headline': 'More Zika patients reported in Fort Worth',\n",
       "  'countries': None,\n",
       "  'cities': 'Fort Worth'},\n",
       " {'headline': 'Zika symptoms spotted in Boynton Beach',\n",
       "  'countries': None,\n",
       "  'cities': 'Boynton Beach'},\n",
       " {'headline': 'Outbreak of Zika in Portoviejo',\n",
       "  'countries': None,\n",
       "  'cities': 'Portoviejo'},\n",
       " {'headline': 'Influenza Exposure in Muscat',\n",
       "  'countries': None,\n",
       "  'cities': 'Muscat'},\n",
       " {'headline': 'Rumors about Rabies spreading in Jerusalem have been refuted',\n",
       "  'countries': None,\n",
       "  'cities': 'Jerusalem'},\n",
       " {'headline': 'More Zika patients reported in Indang',\n",
       "  'countries': None,\n",
       "  'cities': 'Indang'},\n",
       " {'headline': 'Suva authorities confirmed the spread of Rotavirus',\n",
       "  'countries': None,\n",
       "  'cities': 'Suva'},\n",
       " {'headline': 'More Zika patients reported in Bella Vista',\n",
       "  'countries': None,\n",
       "  'cities': 'Bella Vista'},\n",
       " {'headline': 'Zika Outbreak in Wichita Falls',\n",
       "  'countries': None,\n",
       "  'cities': 'Wichita Falls'}]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headline_cities_and_countries = [\n",
    "    find_city_and_country_in_headline(headline) for headline in data\n",
    "]\n",
    "headline_cities_and_countries[-10:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That looks pretty good. It won't always be perfect, but it looks to capture most of the cities and countries. We can now write this as json for loading back in."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving Data\n",
    "\n",
    "We can save our list of dictionaries as json. This format can be easily read in base Python and be a number of libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-10T17:07:31.522676Z",
     "start_time": "2019-10-10T17:07:31.516911Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "save_file = \"../data/headline_cities_and_countries.json\"\n",
    "with open(save_file, \"w\") as fout:\n",
    "    fout.write(json.dumps(headline_cities_and_countries))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's quickly make sure we can load this back in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-10T17:07:31.529400Z",
     "start_time": "2019-10-10T17:07:31.524486Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(save_file, \"r\") as fin:\n",
    "    check_data = json.loads(fin.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-10T17:07:31.538403Z",
     "start_time": "2019-10-10T17:07:31.532000Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'headline': 'Authorities are Worried about the Spread of Varicella in Clovis',\n",
       "  'countries': None,\n",
       "  'cities': 'Clovis'},\n",
       " {'headline': 'More Zika patients reported in Fort Worth',\n",
       "  'countries': None,\n",
       "  'cities': 'Fort Worth'},\n",
       " {'headline': 'Zika symptoms spotted in Boynton Beach',\n",
       "  'countries': None,\n",
       "  'cities': 'Boynton Beach'},\n",
       " {'headline': 'Outbreak of Zika in Portoviejo',\n",
       "  'countries': None,\n",
       "  'cities': 'Portoviejo'},\n",
       " {'headline': 'Influenza Exposure in Muscat',\n",
       "  'countries': None,\n",
       "  'cities': 'Muscat'},\n",
       " {'headline': 'Rumors about Rabies spreading in Jerusalem have been refuted',\n",
       "  'countries': None,\n",
       "  'cities': 'Jerusalem'},\n",
       " {'headline': 'More Zika patients reported in Indang',\n",
       "  'countries': None,\n",
       "  'cities': 'Indang'},\n",
       " {'headline': 'Suva authorities confirmed the spread of Rotavirus',\n",
       "  'countries': None,\n",
       "  'cities': 'Suva'},\n",
       " {'headline': 'More Zika patients reported in Bella Vista',\n",
       "  'countries': None,\n",
       "  'cities': 'Bella Vista'},\n",
       " {'headline': 'Zika Outbreak in Wichita Falls',\n",
       "  'countries': None,\n",
       "  'cities': 'Wichita Falls'}]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_data[-10:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks to be in shape!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-10T17:07:31.544532Z",
     "start_time": "2019-10-10T17:07:31.540355Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'headline': 'Zika Outbreak Hits Miami',\n",
       "  'countries': None,\n",
       "  'cities': 'Miami'},\n",
       " {'headline': 'Could Zika Reach New York City?',\n",
       "  'countries': None,\n",
       "  'cities': 'New York City'},\n",
       " {'headline': 'First Case of Zika in Miami Beach',\n",
       "  'countries': None,\n",
       "  'cities': 'Miami Beach'},\n",
       " {'headline': 'Mystery Virus Spreads in Recife, Brazil',\n",
       "  'countries': 'Brazil',\n",
       "  'cities': 'Recife'},\n",
       " {'headline': 'Dallas man comes down with case of Zika',\n",
       "  'countries': None,\n",
       "  'cities': 'Dallas'}]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_data[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also save out the mappings. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-10T17:07:31.563936Z",
     "start_time": "2019-10-10T17:07:31.546924Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(\"../data/city_accent_mapping.json\", \"w\") as fout:\n",
    "    fout.write(json.dumps(city_accent_mapping))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-10T17:07:31.572944Z",
     "start_time": "2019-10-10T17:07:31.565802Z"
    }
   },
   "outputs": [],
   "source": [
    "with open(\"../data/country_accent_mapping.json\", \"w\") as fout:\n",
    "    fout.write(json.dumps(country_accent_mapping))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Producing a DataFrame\n",
    "\n",
    "We can directly convert our results into a Pandas DataFrame by reading in the json. The Pandas DataFrame is like a spreadsheet in Python and allows us to quickly analyze and manipulate our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-10T17:09:42.932319Z",
     "start_time": "2019-10-10T17:09:42.896098Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>headline</th>\n",
       "      <th>countries</th>\n",
       "      <th>cities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Zika Outbreak Hits Miami</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Miami</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Could Zika Reach New York City?</td>\n",
       "      <td>NaN</td>\n",
       "      <td>New York City</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>First Case of Zika in Miami Beach</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Miami Beach</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mystery Virus Spreads in Recife, Brazil</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>Recife</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dallas man comes down with case of Zika</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Dallas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Trinidad confirms first Zika case</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Trinidad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Zika Concerns are Spreading in Houston</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Houston</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Geneve Scientists Battle to Find Cure</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Geneve</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>The CDC in Atlanta is Growing Worried</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Atlanta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Zika Infested Monkeys in Sao Paulo</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Sao Paulo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  headline countries         cities\n",
       "0                 Zika Outbreak Hits Miami       NaN          Miami\n",
       "1          Could Zika Reach New York City?       NaN  New York City\n",
       "2        First Case of Zika in Miami Beach       NaN    Miami Beach\n",
       "3  Mystery Virus Spreads in Recife, Brazil    Brazil         Recife\n",
       "4  Dallas man comes down with case of Zika       NaN         Dallas\n",
       "5        Trinidad confirms first Zika case       NaN       Trinidad\n",
       "6   Zika Concerns are Spreading in Houston       NaN        Houston\n",
       "7    Geneve Scientists Battle to Find Cure       NaN         Geneve\n",
       "8    The CDC in Atlanta is Growing Worried       NaN        Atlanta\n",
       "9       Zika Infested Monkeys in Sao Paulo       NaN      Sao Paulo"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_json(\"../data/headline_cities_and_countries.json\")\n",
    "data = data.replace({None: np.nan})\n",
    "\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataframe is the final output of the first section. We will use the dataframe in the next part to find geographic coordinates of the headlines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    "\n",
    "In this notebook we:\n",
    "\n",
    "* Processed the headline data \n",
    "* Found the cities and/or countries in the headlines\n",
    "\n",
    "The end deliverable from this section is a Pandas DataFrame with each headline and the city and/or country mentioned in the headline. There may be some errors in the extraction, but we'll move to the next section. If we encounter errors along the way (as is inevitable), we can always correct them as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
